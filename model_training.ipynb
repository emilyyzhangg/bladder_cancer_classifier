{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression, LassoCV, ElasticNetCV\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_curve, roc_auc_score, accuracy_score, recall_score, precision_score, f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from lifelines import KaplanMeierFitter\n",
    "import optuna\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing the data and pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vx/fpmf15096617bm5hj9zlgpn80000gn/T/ipykernel_66798/387192152.py:1: DtypeWarning: Columns (9) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\"./data/UROMOL_TaLG.teachingcohort.csv\")\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"./data/UROMOL_TaLG.teachingcohort.csv\")\n",
    "first_column = df.columns[0]\n",
    "df = df.drop([first_column], axis=1)\n",
    "\n",
    "# drop columns without target featurre\n",
    "df = df.dropna(subset=[\"Recurrence\", \"RFS_time\"])\n",
    "\n",
    "# Define target variable based on recurrence status\n",
    "df[\"risk_group\"] = \"Low\"\n",
    "df.loc[df[\"Recurrence\"] == 1, \"risk_group\"] = pd.qcut(\n",
    "    df.loc[df[\"Recurrence\"] == 1, \"RFS_time\"], \n",
    "    q=[0, 0.5, 1], \n",
    "    labels=[\"Low\", \"High\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing all columns with only one value\n",
    "constant_cols = [col for col in df.columns if df[col].nunique() == 1]\n",
    "df = df.drop(columns=constant_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unnecessary columns (e.g., patient IDs)\n",
    "df = df.drop(columns=[\"UROMOL.ID\", \"Progression\", \"PFS_time.\"], errors=\"ignore\")\n",
    "\n",
    "# Separate features and target\n",
    "y = df[\"risk_group\"] \n",
    "X = df.drop(columns=[\"risk_group\", \"RFS_time\", \"Recurrence\"])  # Features # Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_cols = X.select_dtypes(include=[\"object\", \"category\"]).columns.tolist()\n",
    "numerical_cols = X.select_dtypes(include=[\"number\"]).columns.tolist()\n",
    "\n",
    "# One-hot encode categorical variables\n",
    "encoder = OneHotEncoder(handle_unknown=\"ignore\")\n",
    "X_encoded = pd.DataFrame(encoder.fit_transform(X[categorical_cols]))\n",
    "\n",
    "X_encoded = pd.DataFrame(\n",
    "    encoder.fit_transform(X[categorical_cols]).toarray(),  \n",
    "    columns=encoder.get_feature_names_out(categorical_cols)  \n",
    ")\n",
    "X_encoded.index = X.index\n",
    "\n",
    "X_encoded = X_encoded.rename(columns={\n",
    "    'Tumor.size_< 3 cm': 'Tumor.size_less_three',\n",
    "    'Tumor.size_>= 3 cm': 'Tumor.size_more_three'\n",
    "})\n",
    "\n",
    "# Combine encoded categorical and numerical features\n",
    "X_processed = pd.concat([X_encoded, df[numerical_cols]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN Imputation for missing values\n",
    "imputer = KNNImputer(n_neighbors=5)\n",
    "X_imputed = imputer.fit_transform(X_processed)\n",
    "X_processed_imputed = pd.DataFrame(X_imputed, columns=X_processed.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking for missing values after imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "na_count = X_processed_imputed.isna().any(axis=1).sum()\n",
    "print(na_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "# Train-test split (80-20)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_processed_imputed, y_encoded, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-03-25 23:22:24,935] A new study created in memory with name: no-name-16a4b88a-5e78-45b4-b716-bc896df3993f\n",
      "/var/folders/vx/fpmf15096617bm5hj9zlgpn80000gn/T/ipykernel_66798/3695188130.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  eps = trial.suggest_loguniform(\"eps\", 1e-4, 1.0)\n",
      "[I 2025-03-25 23:24:33,707] Trial 0 finished with value: -0.23398293768115241 and parameters: {'eps': 0.041859998596575666}. Best is trial 0 with value: -0.23398293768115241.\n",
      "/var/folders/vx/fpmf15096617bm5hj9zlgpn80000gn/T/ipykernel_66798/3695188130.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  eps = trial.suggest_loguniform(\"eps\", 1e-4, 1.0)\n",
      "[I 2025-03-25 23:26:41,207] Trial 1 finished with value: -0.23051011151829445 and parameters: {'eps': 0.65273093585505}. Best is trial 1 with value: -0.23051011151829445.\n",
      "/var/folders/vx/fpmf15096617bm5hj9zlgpn80000gn/T/ipykernel_66798/3695188130.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  eps = trial.suggest_loguniform(\"eps\", 1e-4, 1.0)\n",
      "[I 2025-03-25 23:29:31,214] Trial 2 finished with value: -0.2332916321012884 and parameters: {'eps': 0.010542709478701598}. Best is trial 1 with value: -0.23051011151829445.\n",
      "/var/folders/vx/fpmf15096617bm5hj9zlgpn80000gn/T/ipykernel_66798/3695188130.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  eps = trial.suggest_loguniform(\"eps\", 1e-4, 1.0)\n",
      "[I 2025-03-25 23:35:32,343] Trial 3 finished with value: -0.2370669771952918 and parameters: {'eps': 0.0013566134616213475}. Best is trial 1 with value: -0.23051011151829445.\n",
      "/var/folders/vx/fpmf15096617bm5hj9zlgpn80000gn/T/ipykernel_66798/3695188130.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  eps = trial.suggest_loguniform(\"eps\", 1e-4, 1.0)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.500e-03, tolerance: 3.269e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.748e-02, tolerance: 3.269e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.308e-02, tolerance: 3.269e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.265e-03, tolerance: 3.099e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.196e-02, tolerance: 3.099e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.015e-02, tolerance: 3.099e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.827e-02, tolerance: 3.099e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.795e-03, tolerance: 3.414e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.270e-02, tolerance: 3.414e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.006e-01, tolerance: 3.414e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.107e-02, tolerance: 3.227e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.625e-02, tolerance: 2.989e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.776e-03, tolerance: 3.308e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.272e-02, tolerance: 3.227e-03\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "[I 2025-03-25 23:56:45,971] Trial 4 finished with value: -0.23689504377233184 and parameters: {'eps': 0.000347642032913549}. Best is trial 1 with value: -0.23051011151829445.\n",
      "/var/folders/vx/fpmf15096617bm5hj9zlgpn80000gn/T/ipykernel_66798/3695188130.py:3: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  eps = trial.suggest_loguniform(\"eps\", 1e-4, 1.0)\n",
      "[W 2025-03-26 00:00:34,053] Trial 5 failed with parameters: {'eps': 0.0010191879684405744} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"/var/folders/vx/fpmf15096617bm5hj9zlgpn80000gn/T/ipykernel_66798/3695188130.py\", line 5, in objective\n",
      "    return cross_val_score(model, X_train, y_train, cv=5, scoring='neg_mean_squared_error').mean()\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 213, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 719, in cross_val_score\n",
      "    cv_results = cross_validate(\n",
      "                 ^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 213, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 430, in cross_validate\n",
      "    results = parallel(\n",
      "              ^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/parallel.py\", line 67, in __call__\n",
      "    return super().__call__(iterable_with_config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/joblib/parallel.py\", line 1918, in __call__\n",
      "    return output if self.return_generator else list(output)\n",
      "                                                ^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/joblib/parallel.py\", line 1847, in _get_sequential_output\n",
      "    res = func(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/parallel.py\", line 129, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py\", line 1751, in fit\n",
      "    mse_paths = Parallel(\n",
      "                ^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/parallel.py\", line 67, in __call__\n",
      "    return super().__call__(iterable_with_config)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/joblib/parallel.py\", line 1918, in __call__\n",
      "    return output if self.return_generator else list(output)\n",
      "                                                ^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/joblib/parallel.py\", line 1847, in _get_sequential_output\n",
      "    res = func(*args, **kwargs)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/parallel.py\", line 129, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py\", line 1437, in _path_residuals\n",
      "    alphas, coefs, _ = path(X_train, y_train, **path_params)\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 186, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py\", line 361, in lasso_path\n",
      "    return enet_path(\n",
      "           ^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 186, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py\", line 678, in enet_path\n",
      "    model = cd_fast.enet_coordinate_descent(\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "[W 2025-03-26 00:00:34,072] Trial 5 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cross_val_score(model, X_train, y_train, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mneg_mean_squared_error\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mmean()\n\u001b[1;32m      7\u001b[0m study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmaximize\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 8\u001b[0m study\u001b[38;5;241m.\u001b[39moptimize(objective, n_trials\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m15\u001b[39m)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# get best eps\u001b[39;00m\n\u001b[1;32m     11\u001b[0m best_eps \u001b[38;5;241m=\u001b[39m study\u001b[38;5;241m.\u001b[39mbest_params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124meps\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/optuna/study/study.py:475\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    373\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize\u001b[39m(\n\u001b[1;32m    374\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    375\u001b[0m     func: ObjectiveFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    382\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    383\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    384\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[1;32m    385\u001b[0m \n\u001b[1;32m    386\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    473\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[1;32m    474\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 475\u001b[0m     _optimize(\n\u001b[1;32m    476\u001b[0m         study\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    477\u001b[0m         func\u001b[38;5;241m=\u001b[39mfunc,\n\u001b[1;32m    478\u001b[0m         n_trials\u001b[38;5;241m=\u001b[39mn_trials,\n\u001b[1;32m    479\u001b[0m         timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[1;32m    480\u001b[0m         n_jobs\u001b[38;5;241m=\u001b[39mn_jobs,\n\u001b[1;32m    481\u001b[0m         catch\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mtuple\u001b[39m(catch) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(catch, Iterable) \u001b[38;5;28;01melse\u001b[39;00m (catch,),\n\u001b[1;32m    482\u001b[0m         callbacks\u001b[38;5;241m=\u001b[39mcallbacks,\n\u001b[1;32m    483\u001b[0m         gc_after_trial\u001b[38;5;241m=\u001b[39mgc_after_trial,\n\u001b[1;32m    484\u001b[0m         show_progress_bar\u001b[38;5;241m=\u001b[39mshow_progress_bar,\n\u001b[1;32m    485\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/optuna/study/_optimize.py:63\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m---> 63\u001b[0m         _optimize_sequential(\n\u001b[1;32m     64\u001b[0m             study,\n\u001b[1;32m     65\u001b[0m             func,\n\u001b[1;32m     66\u001b[0m             n_trials,\n\u001b[1;32m     67\u001b[0m             timeout,\n\u001b[1;32m     68\u001b[0m             catch,\n\u001b[1;32m     69\u001b[0m             callbacks,\n\u001b[1;32m     70\u001b[0m             gc_after_trial,\n\u001b[1;32m     71\u001b[0m             reseed_sampler_rng\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     72\u001b[0m             time_start\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     73\u001b[0m             progress_bar\u001b[38;5;241m=\u001b[39mprogress_bar,\n\u001b[1;32m     74\u001b[0m         )\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     76\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/optuna/study/_optimize.py:160\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 160\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m _run_trial(study, func, catch)\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[1;32m    164\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/optuna/study/_optimize.py:248\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    241\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    243\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    244\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[1;32m    245\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    246\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[1;32m    247\u001b[0m ):\n\u001b[0;32m--> 248\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/optuna/study/_optimize.py:197\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[1;32m    196\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 197\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m func(trial)\n\u001b[1;32m    198\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    199\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[1;32m    200\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "Cell \u001b[0;32mIn[18], line 5\u001b[0m, in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m      3\u001b[0m eps \u001b[38;5;241m=\u001b[39m trial\u001b[38;5;241m.\u001b[39msuggest_loguniform(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meps\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m1e-4\u001b[39m, \u001b[38;5;241m1.0\u001b[39m)\n\u001b[1;32m      4\u001b[0m model \u001b[38;5;241m=\u001b[39m LassoCV(eps\u001b[38;5;241m=\u001b[39meps, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m43\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cross_val_score(model, X_train, y_train, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mneg_mean_squared_error\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mmean()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    211\u001b[0m         )\n\u001b[1;32m    212\u001b[0m     ):\n\u001b[0;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    223\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:719\u001b[0m, in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, params, pre_dispatch, error_score)\u001b[0m\n\u001b[1;32m    716\u001b[0m \u001b[38;5;66;03m# To ensure multimetric format is not supported\u001b[39;00m\n\u001b[1;32m    717\u001b[0m scorer \u001b[38;5;241m=\u001b[39m check_scoring(estimator, scoring\u001b[38;5;241m=\u001b[39mscoring)\n\u001b[0;32m--> 719\u001b[0m cv_results \u001b[38;5;241m=\u001b[39m cross_validate(\n\u001b[1;32m    720\u001b[0m     estimator\u001b[38;5;241m=\u001b[39mestimator,\n\u001b[1;32m    721\u001b[0m     X\u001b[38;5;241m=\u001b[39mX,\n\u001b[1;32m    722\u001b[0m     y\u001b[38;5;241m=\u001b[39my,\n\u001b[1;32m    723\u001b[0m     groups\u001b[38;5;241m=\u001b[39mgroups,\n\u001b[1;32m    724\u001b[0m     scoring\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscore\u001b[39m\u001b[38;5;124m\"\u001b[39m: scorer},\n\u001b[1;32m    725\u001b[0m     cv\u001b[38;5;241m=\u001b[39mcv,\n\u001b[1;32m    726\u001b[0m     n_jobs\u001b[38;5;241m=\u001b[39mn_jobs,\n\u001b[1;32m    727\u001b[0m     verbose\u001b[38;5;241m=\u001b[39mverbose,\n\u001b[1;32m    728\u001b[0m     fit_params\u001b[38;5;241m=\u001b[39mfit_params,\n\u001b[1;32m    729\u001b[0m     params\u001b[38;5;241m=\u001b[39mparams,\n\u001b[1;32m    730\u001b[0m     pre_dispatch\u001b[38;5;241m=\u001b[39mpre_dispatch,\n\u001b[1;32m    731\u001b[0m     error_score\u001b[38;5;241m=\u001b[39merror_score,\n\u001b[1;32m    732\u001b[0m )\n\u001b[1;32m    733\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cv_results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_score\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    211\u001b[0m         )\n\u001b[1;32m    212\u001b[0m     ):\n\u001b[0;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    223\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:430\u001b[0m, in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, params, pre_dispatch, return_train_score, return_estimator, return_indices, error_score)\u001b[0m\n\u001b[1;32m    427\u001b[0m \u001b[38;5;66;03m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[1;32m    428\u001b[0m \u001b[38;5;66;03m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[1;32m    429\u001b[0m parallel \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39mn_jobs, verbose\u001b[38;5;241m=\u001b[39mverbose, pre_dispatch\u001b[38;5;241m=\u001b[39mpre_dispatch)\n\u001b[0;32m--> 430\u001b[0m results \u001b[38;5;241m=\u001b[39m parallel(\n\u001b[1;32m    431\u001b[0m     delayed(_fit_and_score)(\n\u001b[1;32m    432\u001b[0m         clone(estimator),\n\u001b[1;32m    433\u001b[0m         X,\n\u001b[1;32m    434\u001b[0m         y,\n\u001b[1;32m    435\u001b[0m         scorer\u001b[38;5;241m=\u001b[39mscorers,\n\u001b[1;32m    436\u001b[0m         train\u001b[38;5;241m=\u001b[39mtrain,\n\u001b[1;32m    437\u001b[0m         test\u001b[38;5;241m=\u001b[39mtest,\n\u001b[1;32m    438\u001b[0m         verbose\u001b[38;5;241m=\u001b[39mverbose,\n\u001b[1;32m    439\u001b[0m         parameters\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    440\u001b[0m         fit_params\u001b[38;5;241m=\u001b[39mrouted_params\u001b[38;5;241m.\u001b[39mestimator\u001b[38;5;241m.\u001b[39mfit,\n\u001b[1;32m    441\u001b[0m         score_params\u001b[38;5;241m=\u001b[39mrouted_params\u001b[38;5;241m.\u001b[39mscorer\u001b[38;5;241m.\u001b[39mscore,\n\u001b[1;32m    442\u001b[0m         return_train_score\u001b[38;5;241m=\u001b[39mreturn_train_score,\n\u001b[1;32m    443\u001b[0m         return_times\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    444\u001b[0m         return_estimator\u001b[38;5;241m=\u001b[39mreturn_estimator,\n\u001b[1;32m    445\u001b[0m         error_score\u001b[38;5;241m=\u001b[39merror_score,\n\u001b[1;32m    446\u001b[0m     )\n\u001b[1;32m    447\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m train, test \u001b[38;5;129;01min\u001b[39;00m indices\n\u001b[1;32m    448\u001b[0m )\n\u001b[1;32m    450\u001b[0m _warn_or_raise_about_fit_failures(results, error_score)\n\u001b[1;32m    452\u001b[0m \u001b[38;5;66;03m# For callable scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[1;32m    453\u001b[0m \u001b[38;5;66;03m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[1;32m    454\u001b[0m \u001b[38;5;66;03m# the correct key.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/parallel.py:67\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     62\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     63\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     64\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     66\u001b[0m )\n\u001b[0;32m---> 67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/joblib/parallel.py:1918\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1916\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[1;32m   1917\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 1918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n\u001b[1;32m   1920\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[1;32m   1921\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[1;32m   1922\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[1;32m   1923\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[1;32m   1924\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[1;32m   1925\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/joblib/parallel.py:1847\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1845\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1846\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 1847\u001b[0m res \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1848\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1849\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/parallel.py:129\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    127\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[0;32m--> 129\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:895\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, score_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    893\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[1;32m    894\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 895\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mfit(X_train, y_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[1;32m    897\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m    898\u001b[0m     \u001b[38;5;66;03m# Note fit time as time until error\u001b[39;00m\n\u001b[1;32m    899\u001b[0m     fit_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m start_time\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1472\u001b[0m     )\n\u001b[1;32m   1473\u001b[0m ):\n\u001b[0;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:1751\u001b[0m, in \u001b[0;36mLinearModelCV.fit\u001b[0;34m(self, X, y, sample_weight, **params)\u001b[0m\n\u001b[1;32m   1731\u001b[0m \u001b[38;5;66;03m# We do a double for loop folded in one, in order to be able to\u001b[39;00m\n\u001b[1;32m   1732\u001b[0m \u001b[38;5;66;03m# iterate in parallel on l1_ratio and folds\u001b[39;00m\n\u001b[1;32m   1733\u001b[0m jobs \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1734\u001b[0m     delayed(_path_residuals)(\n\u001b[1;32m   1735\u001b[0m         X,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m train, test \u001b[38;5;129;01min\u001b[39;00m folds\n\u001b[1;32m   1750\u001b[0m )\n\u001b[0;32m-> 1751\u001b[0m mse_paths \u001b[38;5;241m=\u001b[39m Parallel(\n\u001b[1;32m   1752\u001b[0m     n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs,\n\u001b[1;32m   1753\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose,\n\u001b[1;32m   1754\u001b[0m     prefer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthreads\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1755\u001b[0m )(jobs)\n\u001b[1;32m   1756\u001b[0m mse_paths \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mreshape(mse_paths, (n_l1_ratio, \u001b[38;5;28mlen\u001b[39m(folds), \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# The mean is computed over folds.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/parallel.py:67\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     62\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     63\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     64\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     66\u001b[0m )\n\u001b[0;32m---> 67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/joblib/parallel.py:1918\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1916\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[1;32m   1917\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 1918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n\u001b[1;32m   1920\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[1;32m   1921\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[1;32m   1922\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[1;32m   1923\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[1;32m   1924\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[1;32m   1925\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/joblib/parallel.py:1847\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1845\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1846\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 1847\u001b[0m res \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1848\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   1849\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/parallel.py:129\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    127\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[0;32m--> 129\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:1437\u001b[0m, in \u001b[0;36m_path_residuals\u001b[0;34m(X, y, sample_weight, train, test, fit_intercept, path, path_params, alphas, l1_ratio, X_order, dtype)\u001b[0m\n\u001b[1;32m   1434\u001b[0m \u001b[38;5;66;03m# Do the ordering and type casting here, as if it is done in the path,\u001b[39;00m\n\u001b[1;32m   1435\u001b[0m \u001b[38;5;66;03m# X is copied and a reference is kept here\u001b[39;00m\n\u001b[1;32m   1436\u001b[0m X_train \u001b[38;5;241m=\u001b[39m check_array(X_train, accept_sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsc\u001b[39m\u001b[38;5;124m\"\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mdtype, order\u001b[38;5;241m=\u001b[39mX_order)\n\u001b[0;32m-> 1437\u001b[0m alphas, coefs, _ \u001b[38;5;241m=\u001b[39m path(X_train, y_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpath_params)\n\u001b[1;32m   1438\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m X_train, y_train\n\u001b[1;32m   1440\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   1441\u001b[0m     \u001b[38;5;66;03m# Doing this so that it becomes coherent with multioutput.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/_param_validation.py:186\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    184\u001b[0m global_skip_validation \u001b[38;5;241m=\u001b[39m get_config()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskip_parameter_validation\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m global_skip_validation:\n\u001b[0;32m--> 186\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    188\u001b[0m func_sig \u001b[38;5;241m=\u001b[39m signature(func)\n\u001b[1;32m    190\u001b[0m \u001b[38;5;66;03m# Map *args/**kwargs to the function signature\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:361\u001b[0m, in \u001b[0;36mlasso_path\u001b[0;34m(X, y, eps, n_alphas, alphas, precompute, Xy, copy_X, coef_init, verbose, return_n_iter, positive, **params)\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[38;5;129m@validate_params\u001b[39m(\n\u001b[1;32m    189\u001b[0m     {\n\u001b[1;32m    190\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray-like\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msparse matrix\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    219\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams,\n\u001b[1;32m    220\u001b[0m ):\n\u001b[1;32m    221\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute Lasso path with coordinate descent.\u001b[39;00m\n\u001b[1;32m    222\u001b[0m \n\u001b[1;32m    223\u001b[0m \u001b[38;5;124;03m    The Lasso optimization function varies for mono and multi-outputs.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    359\u001b[0m \u001b[38;5;124;03m     [0.2159048  0.4425765  0.23668876]]\u001b[39;00m\n\u001b[1;32m    360\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 361\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m enet_path(\n\u001b[1;32m    362\u001b[0m         X,\n\u001b[1;32m    363\u001b[0m         y,\n\u001b[1;32m    364\u001b[0m         l1_ratio\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m,\n\u001b[1;32m    365\u001b[0m         eps\u001b[38;5;241m=\u001b[39meps,\n\u001b[1;32m    366\u001b[0m         n_alphas\u001b[38;5;241m=\u001b[39mn_alphas,\n\u001b[1;32m    367\u001b[0m         alphas\u001b[38;5;241m=\u001b[39malphas,\n\u001b[1;32m    368\u001b[0m         precompute\u001b[38;5;241m=\u001b[39mprecompute,\n\u001b[1;32m    369\u001b[0m         Xy\u001b[38;5;241m=\u001b[39mXy,\n\u001b[1;32m    370\u001b[0m         copy_X\u001b[38;5;241m=\u001b[39mcopy_X,\n\u001b[1;32m    371\u001b[0m         coef_init\u001b[38;5;241m=\u001b[39mcoef_init,\n\u001b[1;32m    372\u001b[0m         verbose\u001b[38;5;241m=\u001b[39mverbose,\n\u001b[1;32m    373\u001b[0m         positive\u001b[38;5;241m=\u001b[39mpositive,\n\u001b[1;32m    374\u001b[0m         return_n_iter\u001b[38;5;241m=\u001b[39mreturn_n_iter,\n\u001b[1;32m    375\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams,\n\u001b[1;32m    376\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/_param_validation.py:186\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    184\u001b[0m global_skip_validation \u001b[38;5;241m=\u001b[39m get_config()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskip_parameter_validation\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m global_skip_validation:\n\u001b[0;32m--> 186\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    188\u001b[0m func_sig \u001b[38;5;241m=\u001b[39m signature(func)\n\u001b[1;32m    190\u001b[0m \u001b[38;5;66;03m# Map *args/**kwargs to the function signature\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:678\u001b[0m, in \u001b[0;36menet_path\u001b[0;34m(X, y, l1_ratio, eps, n_alphas, alphas, precompute, Xy, copy_X, coef_init, verbose, return_n_iter, positive, check_input, **params)\u001b[0m\n\u001b[1;32m    664\u001b[0m     model \u001b[38;5;241m=\u001b[39m cd_fast\u001b[38;5;241m.\u001b[39menet_coordinate_descent_gram(\n\u001b[1;32m    665\u001b[0m         coef_,\n\u001b[1;32m    666\u001b[0m         l1_reg,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    675\u001b[0m         positive,\n\u001b[1;32m    676\u001b[0m     )\n\u001b[1;32m    677\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m precompute \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[0;32m--> 678\u001b[0m     model \u001b[38;5;241m=\u001b[39m cd_fast\u001b[38;5;241m.\u001b[39menet_coordinate_descent(\n\u001b[1;32m    679\u001b[0m         coef_, l1_reg, l2_reg, X, y, max_iter, tol, rng, random, positive\n\u001b[1;32m    680\u001b[0m     )\n\u001b[1;32m    681\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    682\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    683\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPrecompute should be one of True, False, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m or array-like. Got \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    684\u001b[0m         \u001b[38;5;241m%\u001b[39m precompute\n\u001b[1;32m    685\u001b[0m     )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# for optuna\n",
    "def objective(trial):\n",
    "    eps = trial.suggest_loguniform(\"eps\", 1e-4, 1.0)\n",
    "    model = LassoCV(eps=eps, random_state=43)\n",
    "    return cross_val_score(model, X_train, y_train, cv=5, scoring='neg_mean_squared_error').mean()\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=15)\n",
    "\n",
    "# get best eps\n",
    "best_eps = study.best_params['eps']\n",
    "\n",
    "# train lasso with best eps\n",
    "lasso = LassoCV(alpha=best_eps, random_state=43)\n",
    "lasso.fit(X_train, y_train)\n",
    "\n",
    "# predictions\n",
    "y_pred_lasso = lasso.predict(X_test)\n",
    "y_pred_lasso_proba = lasso.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Elastic Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    alpha = trial.suggest_loguniform(\"alpha\", 1e-5, 10)\n",
    "    l1_ratio = trial.suggest_float(\"l1_ratio\", 0.1, 1.0)\n",
    "\n",
    "    elastic_net = ElasticNetCV(alpha=alpha, l1_ratio=l1_ratio, random_state=43)\n",
    "    score = cross_val_score(elastic_net, X_train, y_train, cv=5, scoring=\"neg_mean_squared_error\").mean()\n",
    "    \n",
    "    return score\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=15)\n",
    "\n",
    "best_params = study.best_params\n",
    "\n",
    "elastic_net = ElasticNetCV(alpha=best_params[\"alpha\"], l1_ratio=best_params[\"l1_ratio\"], random_state=43)\n",
    "elastic_net.fit(X_train, y_train)\n",
    "\n",
    "y_pred_en = elastic_net.predict(X_test)\n",
    "y_pred_en_proba = elastic_net.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    n_estimators = trial.suggest_int(\"n_estimators\", 50, 500)\n",
    "    max_depth = trial.suggest_int(\"max_depth\", 3, 30)\n",
    "    min_samples_split = trial.suggest_int(\"min_samples_split\", 2, 10)\n",
    "    min_samples_leaf = trial.suggest_int(\"min_samples_leaf\", 1, 5)\n",
    "    max_features = trial.suggest_categorical(\"max_features\", [\"sqrt\", \"log2\", None])\n",
    "\n",
    "    random_forest = RandomForestClassifier(\n",
    "        n_estimators=n_estimators,\n",
    "        max_depth=max_depth,\n",
    "        min_samples_split=min_samples_split,\n",
    "        min_samples_leaf=min_samples_leaf,\n",
    "        max_features=max_features,\n",
    "        random_state=43,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    score = cross_val_score(random_forest, X_train, y_train, cv=5, scoring=\"accuracy\").mean()\n",
    "    \n",
    "    return score\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=15)\n",
    "\n",
    "best_params = study.best_params\n",
    "random_forest = RandomForestClassifier(**best_params, random_state=43, n_jobs=-1)\n",
    "random_forest.fit(X_train, y_train)\n",
    "\n",
    "y_pred_rf = random_forest.predict(X_test)\n",
    "y_pred_rf_proba = random_forest.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_gbm(trial):\n",
    "    n_estimators = trial.suggest_int(\"n_estimators\", 50, 500)\n",
    "    learning_rate = trial.suggest_loguniform(\"learning_rate\", 0.01, 0.5)\n",
    "    max_depth = trial.suggest_int(\"max_depth\", 3, 15)\n",
    "    min_samples_split = trial.suggest_int(\"min_samples_split\", 2, 10)\n",
    "    min_samples_leaf = trial.suggest_int(\"min_samples_leaf\", 1, 5)\n",
    "    subsample = trial.suggest_float(\"subsample\", 0.5, 1.0)\n",
    "    max_features = trial.suggest_categorical(\"max_features\", [\"sqrt\", \"log2\", None])\n",
    "\n",
    "    gbm = GradientBoostingClassifier(\n",
    "        n_estimators=n_estimators,\n",
    "        learning_rate=learning_rate,\n",
    "        max_depth=max_depth,\n",
    "        min_samples_split=min_samples_split,\n",
    "        min_samples_leaf=min_samples_leaf,\n",
    "        subsample=subsample,\n",
    "        max_features=max_features,\n",
    "        random_state=43\n",
    "    )\n",
    "\n",
    "    score = cross_val_score(gbm, X_train, y_train, cv=5, scoring=\"accuracy\").mean()\n",
    "    return score\n",
    "\n",
    "study_gbm = optuna.create_study(direction=\"maximize\")\n",
    "study_gbm.optimize(objective_gbm, n_trials=15)\n",
    "\n",
    "best_params_gbm = study_gbm.best_params\n",
    "gbm = GradientBoostingClassifier(**best_params_gbm, random_state=43)\n",
    "gbm.fit(X_train, y_train)\n",
    "\n",
    "y_pred_gbm = gbm.predict(X_test)\n",
    "y_pred_gbm_proba = gbm.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    n_estimators = trial.suggest_int(\"n_estimators\", 50, 500)\n",
    "    learning_rate = trial.suggest_loguniform(\"learning_rate\", 0.01, 0.5)\n",
    "    max_depth = trial.suggest_int(\"max_depth\", 3, 15)\n",
    "    min_child_weight = trial.suggest_int(\"min_child_weight\", 1, 10)\n",
    "    gamma = trial.suggest_loguniform(\"gamma\", 1e-8, 10.0)\n",
    "    subsample = trial.suggest_float(\"subsample\", 0.5, 1.0)\n",
    "    colsample_bytree = trial.suggest_float(\"colsample_bytree\", 0.5, 1.0)\n",
    "\n",
    "    xgb = XGBClassifier(\n",
    "        n_estimators=n_estimators,\n",
    "        learning_rate=learning_rate,\n",
    "        max_depth=max_depth,\n",
    "        min_child_weight=min_child_weight,\n",
    "        gamma=gamma,\n",
    "        subsample=subsample,\n",
    "        colsample_bytree=colsample_bytree,\n",
    "        use_label_encoder=False,\n",
    "        eval_metric=\"logloss\",\n",
    "        random_state=43\n",
    "    )\n",
    "\n",
    "    score = cross_val_score(xgb, X_train, y_train, cv=5, scoring=\"accuracy\").mean()\n",
    "    \n",
    "    return score\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=15)\n",
    "\n",
    "best_params = study.best_params\n",
    "\n",
    "xgb = XGBClassifier(**best_params, use_label_encoder=False, eval_metric=\"logloss\", random_state=43)\n",
    "xgb.fit(X_train, y_train)\n",
    "\n",
    "y_pred_xgb = xgb.predict(X_test)\n",
    "y_pred_xgb_proba = xgb.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_results = {\n",
    "    \"Lasso\":         (y_pred_lasso,  y_pred_lasso_proba),\n",
    "    \"ElasticNet\":    (y_pred_en,    y_pred_en_proba),\n",
    "    \"RandomForest\":  (y_pred_rf,       y_pred_rf_proba),\n",
    "    \"GBM\":           (y_pred_gbm,      y_pred_gbm_proba),\n",
    "    \"XGBoost\":       (y_pred_xgb,      y_pred_xgb_proba)\n",
    "}\n",
    "\n",
    "performance_data = []\n",
    "\n",
    "for model_name, (preds, scores) in model_results.items():\n",
    "    # accuracy\n",
    "    acc = accuracy_score(y_test, preds)\n",
    "\n",
    "    # AUC \n",
    "    auc_val = roc_auc_score(y_test, scores)\n",
    "\n",
    "    # sensitivity - recall for the positive class\n",
    "    sens = recall_score(y_test, preds, pos_label=1)\n",
    "\n",
    "    performance_data.append({\n",
    "        'Model': model_name,\n",
    "        'Accuracy': acc,\n",
    "        'AUC': auc_val,\n",
    "        'Sensitivity': sens\n",
    "    })\n",
    "\n",
    "perf_df = pd.DataFrame(performance_data)\n",
    "print(\"=== Model Performance Summary ===\")\n",
    "display(perf_df)\n",
    "\n",
    "\n",
    "model_names = perf_df['Model'].tolist()\n",
    "\n",
    "# set up majority vote ensemble among chosen models\n",
    "def ensemble_vote(models_list, model_results_dict, threshold):\n",
    "    sum_preds = np.zeros_like(y_test, dtype=int)\n",
    "    for m in models_list:\n",
    "        sum_preds += model_results_dict[m][0] \n",
    "\n",
    "    return (sum_preds >= threshold).astype(int)\n",
    "\n",
    "# majority is 3 votes or more.\n",
    "ensemble_sens_pred = ensemble_vote(model_names, model_results, threshold=3)\n",
    "\n",
    "# evaluate the ensemble\n",
    "def evaluate_ensemble(ensemble_name, ensemble_pred, model_names):\n",
    "    print(f\"\\n{ensemble_name} Ensemble\")\n",
    "    print(\"Using models:\", model_names)\n",
    "\n",
    "    # Confusion Matrix\n",
    "    cm = confusion_matrix(y_test, ensemble_pred)\n",
    "    plt.figure(figsize=(5,4))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.title(f\"{ensemble_name} Ensemble Confusion Matrix\")\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"Actual\")\n",
    "    plt.show()\n",
    "\n",
    "    # Classification Report\n",
    "    print(classification_report(y_test, ensemble_pred))\n",
    "\n",
    "    # Approximate Probability for ROC:\n",
    "    sum_preds = np.zeros_like(y_test, dtype=int)\n",
    "    for m in model_names:\n",
    "        sum_preds += model_results[m][0]\n",
    "    ensemble_score = sum_preds / 5.0\n",
    "\n",
    "    fpr, tpr, _ = roc_curve(y_test, ensemble_score)\n",
    "    auc_val = roc_auc_score(y_test, ensemble_score)\n",
    "    plt.figure(figsize=(6,5))\n",
    "    plt.plot(fpr, tpr, label=f\"{ensemble_name} (AUC={auc_val:.3f})\")\n",
    "    plt.plot([0,1],[0,1],'k--')\n",
    "    plt.title(f\"{ensemble_name} Ensemble ROC Curve\")\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "evaluate_ensemble(\"Top-5 by Sensitivity\", ensemble_sens_pred, best5_sens_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define individual models\n",
    "models = {\n",
    "    \"EN\": LogisticRegression(penalty='l2', max_iter=500),\n",
    "    \"SVM\": SVC(probability=True),\n",
    "    \"KNN\": KNeighborsClassifier(n_neighbors=5),\n",
    "    \"RF\": RandomForestClassifier(n_estimators=100),\n",
    "    \"XGB\": XGBClassifier(use_label_encoder=False, eval_metric=\"logloss\")\n",
    "}\n",
    "\n",
    "# Train models\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "# Ensemble: Voting Classifier (Soft Voting for Confidence Scores)\n",
    "ensemble = VotingClassifier(estimators=list(models.items()), voting=\"soft\")\n",
    "ensemble.fit(X_train, y_train)\n",
    "\n",
    "# Predictions & Confidence Scores\n",
    "y_pred = ensemble.predict(X_test)\n",
    "y_prob = ensemble.predict_proba(X_test)  # Confidence values\n",
    "\n",
    "y_pred_decoded = label_encoder.inverse_transform(y_pred)\n",
    "y_test_decoded = label_encoder.inverse_transform(y_test)\n",
    "\n",
    "# Convert confidence scores to dictionary for better interpretation\n",
    "confidence_scores = [\n",
    "    {category: prob for category, prob in zip(ensemble.classes_, probs)}\n",
    "    for probs in y_prob\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[11  7  1]\n",
      " [ 9  9  1]\n",
      " [ 4  3 11]]\n",
      "\n",
      "Classification Report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "         High       0.46      0.58      0.51        19\n",
      "          Low       0.47      0.47      0.47        19\n",
      "No Recurrence       0.85      0.61      0.71        18\n",
      "\n",
      "     accuracy                           0.55        56\n",
      "    macro avg       0.59      0.55      0.56        56\n",
      " weighted avg       0.59      0.55      0.56        56\n",
      "\n",
      "ROC-AUC Score: 0.7132132132132133\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Evaluate Performance\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test_decoded, y_pred_decoded))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test_decoded, y_pred_decoded))\n",
    "print(\"ROC-AUC Score:\", roc_auc_score(pd.get_dummies(y_test_decoded), y_prob, multi_class=\"ovr\"))\n",
    "\n",
    "# Plot Confusion Matrix\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(confusion_matrix(y_test_decoded, y_pred_decoded), annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=ensemble.classes_, yticklabels=ensemble.classes_)\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kaplan-Meier Survival Curve\n",
    "kmf = KaplanMeierFitter()\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "for group in [1, 2, 0]:\n",
    "    mask = df[\"risk_group\"] == group\n",
    "    kmf.fit(df[\"RFS_time\"][mask], event_observed=(df[\"risk_group\"] != 0))\n",
    "    kmf.plot_survival_function(label=group)\n",
    "\n",
    "plt.title(\"Kaplan-Meier Survival Curve\")\n",
    "plt.xlabel(\"Time (months)\")\n",
    "plt.ylabel(\"Survival Probability\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Model\n",
    "with open(\"ensemble_model.pkl\", \"wb\") as f:\n",
    "    pickle.dump(ensemble, f)\n",
    "\n",
    "# Example Output: First 5 Predictions with Confidence Scores\n",
    "for i in range(5):\n",
    "    print(f\"Prediction: {y_pred[i]}, Confidence Scores: {confidence_scores[i]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
